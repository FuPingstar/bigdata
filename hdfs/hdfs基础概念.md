+
HDFS 全称： __Hadoop Distributed FileSystem__

hadoop 核心两大组件之一

***hadoop所要解决的两大核心问题***<br>
	`1.大数据的分布式存储`
	`2.大数据的分布式处理`

分布式文件系统的HDFS简介
	hdfs实现目标：<br>
		`1.兼容廉价的硬件设备(硬件错误，因此需要冗余)`
			硬件错误是常态而不是异常，HDFS可能由成千上百的服务器构成，每个文件系统上存储这文件系统的部分数据。我们面对的现实是构成系统的组件数目是巨大的，而且任一组件都有可能失效。这意味着总是有一部分HDFS组件不是在工作。因此错误检测和快速、自动的恢复是HDFS最核心的架构目标。
		`2.实现流数据读写`
			流式数据访问是什么意思:
			特点就是像流水一样，不是一次过来而是一点一点“流”过来。而你处理流式数据也是一点一点处理，如果是全部收到数据以后再处理，那么延迟会很大，而且在很多场合会消耗大量内存
		运行在hdfs上的应用和普通的应用不同，需要流式访问他们的数据集。HDFS的设计中更多的考虑到了数据的批处理，而不是用户交互处理。比之前数据访问的低延迟问题，更关键的在于数据访问的高吞吐量
		`3.支持大数据集`
			运行在HDFS上的应用具有很大的数据集。HDFS一个典型文件大小一般都在G字节至T字节。因此HDFS被调节以支持大文件存储，他应该能提供整体上高的数据传输带宽，能在一个集群里扩展到数百个节。一个单一的HDFS实例应该能支撑数以千万计的节点。
		`4.支持简单的文件模型`
			HDFS应用需要一个 一次写入，多次读取 的文件访问模型。一个文件经过创建，写入和关闭之后就不需要改变。这一假设简化了数据一致性问题，并且使高吞吐量的数据访问成为可能。Map/Reduce应用或者网络爬虫应用都非常适合这个模型，目前还有个计划在将来扩充这个模型，使之支持文件的附加写操作。
		`5.强大的跨平台兼容性`
		`6.移动计算比移动数据划算`
			一个应用请求的计算，离他操作的数据越近就越高效，在数据达到海量级别的时候更是如此。因为这样就能降低网络阻塞的影响，提高系统数据的吞吐量。将计算移动到数据附近 ，比之将数据移动到应用所在出显然更好。Hdfs为应用提供了将他们自己移动到数据附近的接口。
	hdfs自身的局限性
		1.不适合低延迟的数据访问
		2.无法高效存储大量小文件
		3.不支持多用户写入及任意修改文件


HDFS相关概念
	1.块
		HDFS中最核心的概念
		普通文件块的作用：为了分摊磁盘读写开销也就是在大量数据间分摊磁盘寻址的开销
		HDFS块的区别：
			hdfs的一个块要比普通文件系统大的多
		设计目的：
			支持面向大规模数据存储
			降低分布式节点的寻址开销
		 缺点：
			如果块过大会导致MapReduce就一两个任务在执行完全牺牲了MapReduce的并行度，发挥不了分布式并行处理的效果
		设计好处
			1.支持大规模文件存储
			2.简化系统设计
			3.适合数据备份
	2.名称节点 ---整个HDFS集群的管家  负责管理分布式文件系统的命名空间，保存了两个核心的数据结构，即FsImage和Editlog
		元数据：（数据目录）
			1.文件是什么
			2.文件被分成多少块
			3.每个块和文件是怎么映射的
			4.每个块被存储在哪个服务器上面
		核心结构
			FsImage:维护系统文件树以及文件树中的所有文件和目录的元数据
				1.文件的复制等级
				2.修改和访问时间
				3.访问权限
				4.块大小以及组成文件的块
			EditLog:记录对数据进行的诸如创建、删除、重命名等操作
			hdfs启动以后，把磁盘中的hdfs的FsImage文件里面的内容读取到内存，与EditLog的内容进行合并，得到最新的元数据信息，名称节点保存新的FsImage,删除旧的，创建一个空的EditLog.
		第二名称节点：解决Editlog不断增大，还可以作为名称节点的冷备份
			  第二名称节点会不断的和名称节点进行通信，在某个阶段会请求名称节点停止使用EditLog文件，名称节点停止使用EditLog,生成一个新的edits.new文件，相当与生成一个新的EditLog,
			  第二名称节点取走旧的EdiLog，第二名称节点以Http Get的方式把FsImage和EditLog下载到本地，进行合并，得到一个新的FsImage，发送给名称节点，名称节点会把edits.new更改成edit，
			  既实现了不断增大的EditLog和FsImage的合并，又实现了冷备份的效果。
	3.数据节点 ---存储实际数据		 
HDFS体系结构
	HDFS命名空间
		目录
		文件
		块
	通信协议 ： TCP/ip  远程： RPC
		1.所有的HDFS通信协议都是构建在TCP/IP协议基础上的
		2.客户端通过一个可以配置的端口向名称节点主动发起TCP连接，并和i用客户端协议与名称节点进行交互
		3.名称节点与数据节点之间则使用数据节点协议来进行交互
		4.客户端与数据节点之间的交互是通过RPC(Remote Procedure Call)来实现的。在设计上，名称节点不会主动发起RPC，而是响应来自客户端和虎居节点的RPC请求
	局限性：
		命名空间限制：名称节点是保存在内存当中的，因此，名称节点能够容纳的对象（文件，块）的个数会受到空间大小的限制
		性能的瓶颈：整个分布式文件系统的吞吐量，受限于单个名称节点的吞吐量
		隔离问题：由于集群中只有一个名称节点，只有一个命名空间，因此无法对应用程序进行隔离
		集群的可用性：一旦这个唯一的名称节点发生故障，会导致整个集群变得不可用

HDFS存储原理
	1.冗余数据保存问题
		1.加快数据传输速度
		2.容易检查数据错误
		3.保证数据的可靠性		
	2.数据保存策略问题
		第一个副本存放在上传文件的数据节点上，第二个副本存放在与第一个副本所属机架不同的节点上，第三个副本存放在与第一个副本所属机架相同的节点上，后面的随即存放
		数据读取(就近读取)
			HDFS提供了一个API可以确定一个数据节点所属机架的ID，客户端也可以调用API获取自己所属机架的ID
			当客户端读取数据时，从名称节点获得数据块不同副本的存放位置列表，列表中包含可副本所在的数据节点，可以调用API来确定客户端和这些数据节点所属的机架ID，当发现了某个数据块副本对应的机架ID和客户端对应的机架ID相同时，就优先选择副本读取数据，如果没有发现，就随即选择一个副本读取数据
	3.数据恢复的问题		
		1.名称节点出错
			冷备份，备份到第二名称节点SeconaryNameNode,名称节点出错，暂停一段时间，把相关的元数据信息从SeconaryNameNode拿过来，继续服务（haddop1.0，hadoop2.0会进行热备份）。
		2.数据节点出错
			如何探测数据节点出错
				数据节点不断通过远程功能给名称节点发送心跳信息，如果名称节点在一个周期接受不到数据节点的心跳信息，则会把此数据节点标记为宕机，复制数据到其他正常节点
			 hdfs优点：冗余数据的位置可以不断变化，不止是出错的时候，负载均衡
		3.数据本身出错
			如何探测数据出错？
				校验码机制

数据读取过程







查看fsimage和editslog：
	这两种文件是经过序列化的，费文本的，不能直接查看的，Hadoop
X中，hdfs提供了查看这两种文件的工具。
命令hdfs oiv用于将fsimage文件转换成其他格式的，如文本文件，xml文件

hdfs ovi
必须参数
	-i -inputfile<arg> 输入Fsimage文件
	-o -outputFile<arg>输出转换后的文件，如果存在，则会覆盖
可选参数
	-p -processor <arg> 将fsimage文件转换成哪种格式，默认为ls
	-h -help




