
HDFS 全称： __Hadoop Distributed FileSystem__

hadoop 核心两大组件之一<br>

***hadoop所要解决的两大核心问题***<br>
	`1.大数据的分布式存储`<br>
	`2.大数据的分布式处理`<br>

分布式文件系统的HDFS简介<br>
	hdfs实现目标：<br>
		`1.兼容廉价的硬件设备(硬件错误，因此需要冗余)`<br>
			<p style="text-indent:2em">硬件错误是常态而不是异常，HDFS可能由成千上百的服务器构成，每个文件系统上存储这文件系统的部分数据。我们面对的现实是构成系统的组件数目是巨大的，而且任一组件都有可能失效。这意味着总是有一部分HDFS组件不是在工作。因此错误检测和快速、自动的恢复是HDFS最核心的架构目标。</p>
		`2.实现流数据读写`<br>
		流式数据访问是什么意思:<br>
		<p style="text-indent:2em">特点就是像流水一样，不是一次过来而是一点一点“流”过来。而你处理流式数据也是一点一点处理，如果是全部收到数据以后再处理，那么延迟会很大，而且在很多场合会消耗大量内存</p>
		<p style="text-indent:2em">运行在hdfs上的应用和普通的应用不同，需要流式访问他们的数据集。HDFS的设计中更多的考虑到了数据的批处理，而不是用户交互处理。比之前数据访问的低延迟问题，更关键的在于数据访问的高吞吐量</p>
		`3.支持大数据集`<br>
		<p style="text-indent:2em">运行在HDFS上的应用具有很大的数据集。HDFS一个典型文件大小一般都在G字节至T字节。因此HDFS被调节以支持大文件存储，他应该能提供整体上高的数据传输带宽，能在一个集群里扩展到数百个节。一个单一的HDFS实例应该能支撑数以千万计的节点。</p>
		`4.支持简单的文件模型`<br>
		<p style="text-indent:2em">HDFS应用需要一个 一次写入，多次读取 的文件访问模型。一个文件经过创建，写入和关闭之后就不需要改变。这一假设简化了数据一致性问题，并且使高吞吐量的数据访问成为可能。Map/Reduce应用或者网络爬虫应用都非常适合这个模型，目前还有个计划在将来扩充这个模型，使之支持文件的附加写操作。</p>
		`5.强大的跨平台兼容性`<br>
		`6.移动计算比移动数据划算`<br>
		<p style="text-indent:2em">一个应用请求的计算，离他操作的数据越近就越高效，在数据达到海量级别的时候更是如此。因为这样就能降低网络阻塞的影响，提高系统数据的吞吐量。将计算移动到数据附近 ，比之将数据移动到应用所在出显然更好。Hdfs为应用提供了将他们自己移动到数据附近的接口。</p>
	hdfs自身的局限性<br>
		1.不适合低延迟的数据访问<br>
		2.无法高效存储大量小文件<br>
		3.不支持多用户写入及任意修改文件<br>


HDFS相关概念<br>
	1.块<br>
		HDFS中最核心的概念<br>
		普通文件块的作用：为了分摊磁盘读写开销也就是在大量数据间分摊磁盘寻址的开销<br>
		HDFS块的区别：<br>
			hdfs的一个块要比普通文件系统大的多<br>
		设计目的：<br>
			支持面向大规模数据存储<br>
			降低分布式节点的寻址开销<br>
		 缺点：<br>
			如果块过大会导致MapReduce就一两个任务在执行完全牺牲了MapReduce的并行度，发挥不了分布式并行处理的效果<br>
		设计好处<br>
			1.支持大规模文件存储<br>
			2.简化系统设计<br>
			3.适合数据备份<br>
	2.名称节点 ---整个HDFS集群的管家  负责管理分布式文件系统的命名空间，保存了两个核心的数据结构，即FsImage和Editlog<br>
		元数据：（数据目录）<br>
			1.文件是什么<br>
			2.文件被分成多少块<br>
			3.每个块和文件是怎么映射的<br>
			4.每个块被存储在哪个服务器上面<br>
		核心结构<br>
			FsImage:维护系统文件树以及文件树中的所有文件和目录的元数据<br>
				1.文件的复制等级<br>
				2.修改和访问时间<br>
				3.访问权限<br>
				4.块大小以及组成文件的块<br>
			EditLog:记录对数据进行的诸如创建、删除、重命名等操作<br>
			hdfs启动以后，把磁盘中的hdfs的FsImage文件里面的内容读取到内存，与EditLog的内容进行合并，得到最新的元数据信息，名称节点保存新的FsImage,删除旧的，创建一个空的EditLog.<br>
		第二名称节点：解决Editlog不断增大，还可以作为名称节点的冷备份<br>
			  第二名称节点会不断的和名称节点进行通信，在某个阶段会请求名称节点停止使用EditLog文件，名称节点停止使用EditLog,生成一个新的edits.new文件，相当与生成一个新的EditLog,
			  第二名称节点取走旧的EdiLog，第二名称节点以Http Get的方式把FsImage和EditLog下载到本地，进行合并，得到一个新的FsImage，发送给名称节点，名称节点会把edits.new更改成edit，
			  既实现了不断增大的EditLog和FsImage的合并，又实现了冷备份的效果。<br>
	3.数据节点 ---存储实际数据		 <br>
HDFS体系结构<br>
	HDFS命名空间<br>
		目录<br>
		文件<br>
		块<br>
	通信协议 ： TCP/ip  远程： RPC<br>
		1.所有的HDFS通信协议都是构建在TCP/IP协议基础上的<br>
		2.客户端通过一个可以配置的端口向名称节点主动发起TCP连接，并且用客户端协议与名称节点进行交互<br>
		3.名称节点与数据节点之间则使用数据节点协议来进行交互<br>
		4.客户端与数据节点之间的交互是通过RPC(Remote Procedure Call)来实现的。在设计上，名称节点不会主动发起RPC，而是响应来自客户端和数据节点的RPC请求<br>
	局限性：<br>
		命名空间限制：名称节点是保存在内存当中的，因此，名称节点能够容纳的对象（文件，块）的个数会受到空间大小的限制<br>
		性能的瓶颈：整个分布式文件系统的吞吐量，受限于单个名称节点的吞吐量<br>
		隔离问题：由于集群中只有一个名称节点，只有一个命名空间，因此无法对应用程序进行隔离<br>
		集群的可用性：一旦这个唯一的名称节点发生故障，会导致整个集群变得不可用<br>

HDFS存储原理<br>
	1.冗余数据保存问题<br>
		1.加快数据传输速度<br>
		2.容易检查数据错误<br>
		3.保证数据的可靠性	<br>	
	2.数据保存策略问题<br>
		<p style="text-indent:2em">第一个副本存放在上传文件的数据节点上，第二个副本存放在与第一个副本所属机架不同的节点上，第三个副本存放在与第一个副本所属机架相同的节点上，后面的随即存放<p>
		数据读取(就近读取)<br>
			HDFS提供了一个API可以确定一个数据节点所属机架的ID，客户端也可以调用API获取自己所属机架的ID
			当客户端读取数据时，从名称节点获得数据块不同副本的存放位置列表，列表中包含可副本所在的数据节点，可以调用API来确定客户端和这些数据节点所属的机架ID，当发现了某个数据块副本对应的机架ID和客户端对应的机架ID相同时，就优先选择副本读取数据，如果没有发现，就随即选择一个副本读取数据<br>
	3.数据恢复的问题		<br>
		1.名称节点出错<br>
			冷备份，备份到第二名称节点SeconaryNameNode,名称节点出错，暂停一段时间，把相关的元数据信息从SeconaryNameNode拿过来，继续服务（haddop1.0，hadoop2.0会进行热备份）。<br>
		2.数据节点出错<br>
			如何探测数据节点出错<br>
				数据节点不断通过远程功能给名称节点发送心跳信息，如果名称节点在一个周期接受不到数据节点的心跳信息，则会把此数据节点标记为宕机，复制数据到其他正常节点
			 hdfs优点：冗余数据的位置可以不断变化，不止是出错的时候，负载均衡<br>
		3.数据本身出错<br>
		如何探测数据出错？<br>
		通过校验和。因为每个chunk中都有一个校验位，一个个chunk构成packet，一个个packet最终形成block，故可在block上求校验和。

		HDFS 的client端即实现了对 HDFS 文件内容的校验和 (checksum) 检查。当客户端创建一个新的HDFS文件时候，分块后会计算这个文件每个数据块的校验和，此校验和会以一个隐藏文件形式保存在同一个 HDFS 命名空间下。当client端从HDFS中读取文件内容后，它会检查分块时候计算出的校验和（隐藏文件里）和读取到的文件块中校验和是否匹配，如果不匹配，客户端可以选择从其他 Datanode 获取该数据块的副本。











